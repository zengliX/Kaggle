{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Simple densely connected neural network to predict output, also contains preprocessing of the dataset\n",
    "    such as encoding the categoricals into one_hot vectors and crossing out features which were constant.\n",
    "    K-folds cross validation has also been implemented\n",
    "    \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#Constants\n",
    "PATH = './data/'\n",
    "TRAIN = 'train.csv'\n",
    "TEST = 'test.csv'\n",
    "SUBMIT = False\n",
    "LOGGING = 100\n",
    "\n",
    "\n",
    "FEATURE_DROP = ['X11', 'X93', 'X107', 'X223', 'X235', 'X268', 'X289', \n",
    "'X290', 'X293', 'X297', 'X330', 'X347'] # constant features\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def one_hot(category, categories_dict):\n",
    "    one_hot = np.zeros((1, len(categories_dict)), dtype='float32')\n",
    "    idx = categories_dict[category[0]]\n",
    "    one_hot.flat[idx] = 1\n",
    "    \n",
    "    return one_hot\n",
    "    \n",
    "\n",
    "# Helper class to perform K-Folds Validation splitting\n",
    "class CrossValidationFolds(object):\n",
    "    \n",
    "    def __init__(self, data, labels, num_folds, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.num_folds = num_folds\n",
    "        self.current_fold = 0\n",
    "        \n",
    "        # Shuffle Dataset\n",
    "        if shuffle:\n",
    "            perm = np.random.permutation(self.data.shape[0])\n",
    "            data = data[perm]\n",
    "            labels = labels[perm]\n",
    "    \n",
    "    def split(self):\n",
    "        current = self.current_fold\n",
    "        size = int(self.data.shape[0]/self.num_folds)\n",
    "        \n",
    "        index = np.arange(self.data.shape[0])\n",
    "        lower_bound = index >= current*size\n",
    "        upper_bound = index < (current + 1)*size\n",
    "        cv_region = lower_bound*upper_bound\n",
    "\n",
    "        cv_data = self.data[cv_region]\n",
    "        train_data = self.data[~cv_region]\n",
    "        \n",
    "        cv_labels = self.labels[cv_region]\n",
    "        train_labels = self.labels[~cv_region]\n",
    "        \n",
    "        self.current_fold += 1\n",
    "        return (train_data, train_labels), (cv_data, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV Data...\n",
      "Data Read\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Data\n",
    "print('Reading CSV Data...')\n",
    "train_df = pd.read_csv(PATH + TRAIN)\n",
    "test_df = pd.read_csv(PATH + TEST)\n",
    "\n",
    "num_examples = train_df.shape[0]  # Both the training and test set have the same # of examples\n",
    "print('Data Read\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 130.81,   88.53,   76.26, ...,  109.22,   87.48,  110.85])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ***Pre preocessing***\n",
    "# Extracting targets\n",
    "target = train_df['y'].values\n",
    "target = target.reshape(num_examples, 1)\n",
    "del train_df['y']\n",
    "\n",
    "# Extracting ID Columns \n",
    "ID = test_df['ID'].values.reshape(num_examples)\n",
    "del train_df['ID']\n",
    "del test_df['ID']\n",
    "\n",
    "# Delete constant features\n",
    "for feature in FEATURE_DROP:\n",
    "    del train_df[feature]\n",
    "    del test_df[feature]\n",
    "    # print('Dropped Feature {}'.format(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical and binary features\n",
    "categoricals = train_df.columns[train_df.dtypes == object] # column names\n",
    "binaries = train_df.columns[train_df.dtypes == 'int64'] # column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **Encode categoricals into one_hot vectors**\n",
    "categoricals_train = np.empty((num_examples, 0))\n",
    "categoricals_test = np.empty((num_examples, 0))\n",
    "\n",
    "# Done in a feature by feature basis\n",
    "for feature in categoricals:\n",
    "    union = pd.Series(train_df[feature].tolist() +test_df[feature].tolist()).unique()\n",
    "    union.sort()\n",
    "    \n",
    "    # Construct dict of categories in feaure\n",
    "    feature_dict = {}\n",
    "    for i in range(len(union)):\n",
    "        feature_dict[union[i]] = i\n",
    "        \n",
    "    # Create one_hot accumulator\n",
    "    train_one_hot = np.empty((0, len(union)))\n",
    "    test_one_hot = np.empty((0, len(union)))\n",
    "    \n",
    "    # Create one_hot for each feature separetely, not a vectorized implementation and somewhat obscure\n",
    "    for i in range(train_df.shape[0]):\n",
    "        train_one_hot = np.concatenate((train_one_hot, one_hot(train_df[feature].values,feature_dict)))\n",
    "        test_one_hot = np.concatenate((test_one_hot, one_hot(test_df[feature].values,feature_dict)))\n",
    "\n",
    "    # Concatenate one_hot of each features into one_hot of all categoricals\n",
    "    categoricals_train = np.concatenate((categoricals_train, train_one_hot), axis=1)\n",
    "    categoricals_test = np.concatenate((categoricals_test, test_one_hot), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 211)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate one_hot categoricals and binaries into a full input dataset\n",
    "train_data = np.concatenate((categoricals_train, train_df[binaries].values.astype('float32')), axis=1)\n",
    "test_input = np.concatenate((categoricals_test, test_df[binaries].values.astype('float32')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 567)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's get Tensorflowy, we now build our network, it will be a fairly simple 2 hidden layers densely connected network\n",
    "# k-fold cross validation is now implementes and we can play with hyperparameter tuning\n",
    "device = \"/gpu:0\"\n",
    "config = tf.ConfigProto(allow_soft_placement=True,  device_count = {'GPU': 1})\n",
    "config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "MAX_ITER = 600\n",
    "LEARNING_RATE = 3e-4\n",
    "LAYERS = [2048, 2048]\n",
    "FOLDS = 5\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMIT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current fold: 1\n",
      "\n",
      "Starting Training...\n",
      "Step 0, Train MSE:  10454.57 | CV MSE:  10562.62\n",
      "Step 100, Train MSE:  80.03 | CV MSE:  73.62\n",
      "Step 200, Train MSE:  69.59 | CV MSE:  66.48\n",
      "Step 300, Train MSE:  65.73 | CV MSE:  70.07\n",
      "Step 400, Train MSE:  59.41 | CV MSE:  68.66\n",
      "Step 500, Train MSE:  55.74 | CV MSE:  71.31\n",
      "\n",
      "Training Finished, Training MSE:  52.76 | R_squared:  0.67561\n",
      "                 Validation MSE:  75.26 | R_squared:  0.50752\n",
      "\n",
      "Current fold: 2\n",
      "\n",
      "Starting Training...\n",
      "Step 0, Train MSE:  8373.96 | CV MSE:  8712.18\n",
      "Step 100, Train MSE:  63.57 | CV MSE:  128.12\n",
      "Step 200, Train MSE:  54.22 | CV MSE:  121.83\n",
      "Step 300, Train MSE:  49.20 | CV MSE:  123.43\n",
      "Step 400, Train MSE:  44.84 | CV MSE:  123.10\n",
      "Step 500, Train MSE:  41.00 | CV MSE:  121.96\n",
      "\n",
      "Training Finished, Training MSE:  39.25 | R_squared:  0.73746\n",
      "                 Validation MSE:  125.63 | R_squared:  0.38508\n",
      "\n",
      "Current fold: 3\n",
      "\n",
      "Starting Training...\n",
      "Step 0, Train MSE:  11004.44 | CV MSE:  10983.63\n",
      "Step 100, Train MSE:  78.07 | CV MSE:  69.18\n",
      "Step 200, Train MSE:  68.72 | CV MSE:  66.21\n",
      "Step 300, Train MSE:  62.53 | CV MSE:  64.96\n",
      "Step 400, Train MSE:  58.80 | CV MSE:  66.12\n",
      "Step 500, Train MSE:  54.72 | CV MSE:  66.48\n",
      "\n",
      "Training Finished, Training MSE:  51.04 | R_squared:  0.68678\n",
      "                 Validation MSE:  66.66 | R_squared:  0.56088\n",
      "\n",
      "Current fold: 4\n",
      "\n",
      "Starting Training...\n",
      "Step 0, Train MSE:  11124.99 | CV MSE:  11129.21\n",
      "Step 100, Train MSE:  80.15 | CV MSE:  87.91\n",
      "Step 200, Train MSE:  66.43 | CV MSE:  78.86\n",
      "Step 300, Train MSE:  60.28 | CV MSE:  77.57\n",
      "Step 400, Train MSE:  56.40 | CV MSE:  78.18\n",
      "Step 500, Train MSE:  53.16 | CV MSE:  80.19\n",
      "\n",
      "Training Finished, Training MSE:  48.46 | R_squared:  0.69928\n",
      "                 Validation MSE:  79.16 | R_squared:  0.50204\n",
      "\n",
      "Current fold: 5\n",
      "\n",
      "Starting Training...\n",
      "Step 0, Train MSE:  8344.51 | CV MSE:  7932.77\n",
      "Step 100, Train MSE:  79.96 | CV MSE:  53.49\n",
      "Step 200, Train MSE:  71.04 | CV MSE:  49.02\n",
      "Step 300, Train MSE:  65.57 | CV MSE:  48.87\n",
      "Step 400, Train MSE:  60.27 | CV MSE:  50.77\n",
      "Step 500, Train MSE:  56.86 | CV MSE:  51.98\n",
      "\n",
      "Training Finished, Training MSE:  53.17 | R_squared:  0.68176\n",
      "                 Validation MSE:  53.32 | R_squared:  0.59653\n",
      "\n",
      "K folds finished\n",
      "Final validation score, MSE:  80.01 | R_squared:  0.51041\n"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation\n",
    "r_squared_log = []\n",
    "mse_log = []\n",
    "data = CrossValidationFolds(train_data, target, FOLDS)\n",
    "with tf.device(device):\n",
    "    with tf.Session(config=config) as sess:\n",
    "        \n",
    "        x = tf.placeholder(tf.float32, shape=[None, train_data.shape[1]])\n",
    "        y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # First Layer\n",
    "        W1 = tf.Variable(tf.truncated_normal([train_data.shape[1], LAYERS[0]], stddev=0.1))\n",
    "        b1 = tf.Variable(tf.constant(0.1, shape=[LAYERS[0]]))\n",
    "\n",
    "        h1 = tf.nn.relu(tf.matmul(x,W1) + b1)\n",
    "\n",
    "        # Second Layer\n",
    "        W2 = tf.Variable(tf.truncated_normal([LAYERS[0], LAYERS[1]], stddev=0.1))\n",
    "        b2 = tf.Variable(tf.constant(0.1, shape=[LAYERS[1]]))\n",
    "\n",
    "        h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)\n",
    "\n",
    "        # Dropout\n",
    "        h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "\n",
    "        # Output Layer\n",
    "        W3 = tf.Variable(tf.truncated_normal([LAYERS[1], 1], stddev=0.1))\n",
    "        b3 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "        y_fc = tf.matmul(h2_drop,W3) + b3\n",
    "\n",
    "        # Loss function and optimizer\n",
    "        loss = tf.losses.mean_squared_error(labels=y_, predictions=y_fc)\n",
    "        train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "        for i in range(FOLDS):\n",
    "            print('Current fold: {}\\n'.format(data.current_fold + 1))\n",
    "            (train_input, train_target), (cv_input, cv_target) = data.split()\n",
    "            \n",
    "            # Start Training\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print('Starting Training...')\n",
    "            for i in range(MAX_ITER):\n",
    "            \n",
    "                if i % LOGGING == 0:\n",
    "                    mse = loss.eval(feed_dict = {x: train_input, y_: train_target, keep_prob: 1.0})\n",
    "                    cv_mse = loss.eval(feed_dict = {x: cv_input, y_: cv_target, keep_prob: 1.0})\n",
    "                    \n",
    "                    print('Step {0}, Train MSE: {1: .2f} | CV MSE: {2: .2f}'.format(i, mse, cv_mse))\n",
    "                train_step.run(feed_dict = {x: train_input, y_: train_target, keep_prob: DROPOUT})\n",
    "            \n",
    "            mse = loss.eval(feed_dict = {x: train_input, y_: train_target, keep_prob: 1.0})\n",
    "            r_squared = 1 - mse/np.var(train_target)\n",
    "            \n",
    "            cv_mse = loss.eval(feed_dict = {x: cv_input, y_: cv_target, keep_prob: 1.0})\n",
    "            cv_r_squared = 1 - cv_mse/np.var(cv_target)\n",
    "            \n",
    "            print('\\nTraining Finished, Training MSE: {0: .2f} | R_squared: {1: .5f}'.format(mse, r_squared))\n",
    "            print('                 Validation MSE: {0: .2f} | R_squared: {1: .5f}\\n'.format(cv_mse, cv_r_squared))\n",
    "            \n",
    "            mse_log.append(cv_mse)\n",
    "            r_squared_log.append(cv_r_squared)\n",
    "            \n",
    "            if SUBMIT:\n",
    "                inference = y_fc.eval(feed_dict = {x: test_input, keep_prob: 1.0})\n",
    "                inference = inference.reshape(num_examples)\n",
    "        \n",
    "        sess.close()\n",
    "        \n",
    "        final_mse = np.array(mse_log).mean()\n",
    "        final_r_squared = np.array(r_squared_log).mean()\n",
    "        \n",
    "        print('K folds finished')\n",
    "        print('Final validation score, MSE: {0: .2f} | R_squared: {1: .5f}'.format(final_mse, final_r_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({'ID': ID, 'y': inference})\n",
    "predictions.to_csv(\"NN.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
